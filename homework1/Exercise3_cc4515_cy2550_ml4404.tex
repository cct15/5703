\documentclass[11pt]{article}
\usepackage[letterpaper]{geometry}
\usepackage[latin1]{inputenc}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{makecell}
\usepackage{url}
\usepackage{setspace}
\usepackage{titlesec}
\titleformat{\subsubsection}[runin]{}{}{}{}[]



\title{Homework 1 Exercise 3}
\author{Chutian Chen cc4515; Congcheng Yan cy2550; Mingrui Liu ml4404}
\graphicspath{{.}}
\pagestyle{plain}

\setstretch{1.25}


\begin{document}
	
\maketitle

\subsection*{Exercise 3}

\subsubsection*{1.}
Let $Y$ has a standard normal distibution. Let $X$ has a normal distribution $N\left(\mu, \sigma^{2}\right)$. We have $$ \sigma^{2} = E(X^2)-(E(X))^2,$$
$$E(X^2) = \sigma^{2} + \mu^{2}.$$
Then we have some conclusions ahout $Y$:
$$E(Y) = 0,$$
$$E(Y^2) = 0 + 1 = 0,$$
$$E(Y^3) = \int_{-\infty}^{\infty} x^{3} \frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2} x^{2}} d x=0.$$
Go back to ${\gamma},$
\begin{align*}
\gamma&=\mathbb{E}\left[R_{1}^{3}\right]\\
&= E[(Y*\sigma + \mu)^3]\\
&= E[Y^3 * \sigma ^3 + 3*y^2*\sigma ^2 *\mu + 3*y*\sigma*\mu^2 + \mu^3]\\
&= E[3*y^2*\mu*\sigma^2 + \mu^3]\\
&= \mu^3 + 3*\mu*\sigma^2
\end{align*}
\subsubsection*{2.}
\begin{enumerate}[(a)]
\item $\frac{1}{n} \sum_{i=1}^{n} R_{i}$ has a normal distribution $\mathbf{N}\left(\mu, \sigma^{2} / n\right)$, so 
\begin{align*}
E[\hat \gamma]  - \gamma &= \mu^3 + 3*\frac{\mu}{n}*\sigma^2 - \mu^3 - 3*\mu*\sigma^2\\
&= 3*\frac{(1-n)\mu}{n}*\sigma^2
\end{align*}
\item Yes, it's consistent.
\begin{align*}
E[\hat \gamma^2] - (E[\hat \gamma])^2 &= \frac {O(n^6) + 6! * C ^{6}_{6}*\sum \limits_{i=1}^{6}R_i}{n^6} - \mu ^6 - O(\frac{1}{n})\\
&\stackrel{n\rightarrow \infty}{\longrightarrow}0
\end{align*}



\end{enumerate}

\subsubsection*{3.}
The bias of  $(\frac{1}{n} \sum_{i=1}^{n} R_{i})^3$ is $3*\frac{(1-n)\mu}{n}*\sigma^2$. From previous work, we also have
$$E[R_1^3]=\gamma = \mu^3 + 3*\mu*\sigma^2$$
$$E[\hat \gamma] = \mu^3 + 3*\frac{\mu}{n}*\sigma^2$$
We can easily have an unbiased estimator of $\mu^3:$ $\frac{n}{n-1}(\frac{1}{n} \sum_{i=1}^{n} R_{i})^3 - \frac{1}{n-1}R_1^3$.

\subsubsection*{4.}
\begin{enumerate}[(a)]
	\item
\begin{align*}
E[\tilde{\gamma}] - \gamma &= \frac{n}{n}E[R_1^3] - E[R_1^3]\\
& = 0
\end{align*}
	\item Yes, it's consistent.


\begin{align*}
E[\tilde \gamma^2] - (E[\tilde \gamma])^2 &= \frac{(\sum\limits_{i=1}^{n}Y_i)^2}{n^2} - (\mu^3+3*\mu*\sigma^2)^2\\
&= \frac{O(n^2)+ n*(n-1)E[R_1^3R_2^3]}{n^2}- (\mu^3+3*\mu*\sigma^2)^2\\
& = (\mu^3+3*\mu*\sigma^2)^2 - (\mu^3+3*\mu*\sigma^2)^2\\
&\stackrel{n\rightarrow \infty}{\longrightarrow}0
\end{align*}


\end{enumerate}


\subsubsection*{5.}
Based on previious work, we have two sufficient statistics $\bar R = \frac{1}{n} \sum_{i=1}^{n} R_{i}$ and $\bar {R^2} = \frac{1}{n} \sum_{i=1}^{n} R_{i}^2$. We also have unbiased and consistent estimator$\tilde{\gamma}=\frac{1}{n} \sum_{i=1}^{n} R_{i}^{3}$.\\
The $MVUE = E[\tilde{\gamma}|T]$.

\begin{align*}
E[\tilde{\gamma}|T] & = E[\frac{1}{n} \sum_{i=1}^{n} R_{i}^{3} | \bar R, \bar {R^2}]\\
&= E[\frac{1}{n} \sum_{i=1}^{n} {R_{i}-\bar R +\bar R}^{3} | \bar R, \bar {R^2}]\\
&= E[\frac{1}{n} \sum_{i=1}^{n} [(R_i - \bar R)^3+3(R_i - \bar R)^2\bar R + 3(R_i - \bar R){\bar R}^2 +{\bar R}^3] | \bar R, \bar {R^2}]\\
&\text{Similar with the derivation of} E(Y) = 0, E(Y^3) = 0, \text{in question 1, we get} \\
&	E(R_i - \bar R) = 0, E((R_i - \bar R)^3) = 0. \text{ So,}\\
E[\tilde{\gamma}|T] & =E[\frac{1}{n} \sum_{i=1}^{n} [3(R_i - \bar R)^2\bar R +{\bar R}^3] | \bar R, \bar {R^2}]\\
&= E[3R_i^2\bar R -6R_i{\bar R}^2 +4{\bar R}^3| \bar R, \bar {R^2}]\\
&=3\bar{R_i^2}\bar R -2{\bar R}^3
\end{align*}


\end{document}
